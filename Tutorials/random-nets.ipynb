{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import netgraph\n",
    "import matplotlib.pylab as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from Qommunity.samplers.hierarchical.advantage_sampler import AdvantageSampler\n",
    "from Qommunity.samplers.regular.leiden_sampler import LeidenSampler\n",
    "from Qommunity.samplers.regular.louvain_sampler import LouvainSampler\n",
    "from Qommunity.samplers.regular.dqm_sampler import DQMSampler\n",
    "#from Qommunity.samplers.regular.bayan_sampler import BayanSampler\n",
    "\n",
    "from Qommunity.searchers.community_searcher.community_searcher import CommunitySearcher\n",
    "from Qommunity.searchers.hierarchical_community_searcher import HierarchicalCommunitySearcher\n",
    "\n",
    "from iterative_searcher.iterative_searcher import IterativeSearcher\n",
    "\n",
    "type_net = 'ER' #'BA' # 'Power-law' #  'DSF' #\n",
    "NUM_NETWORKS = 1\n",
    "MIN_NODES = 10\n",
    "MAX_NODES = 100\n",
    "num_nodes = np.linspace(MIN_NODES, MAX_NODES, MAX_NODES//MIN_NODES)\n",
    "resolution = 1\n",
    "num_runs = 20\n",
    "os.makedirs(f\"./{type_net}\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Properties of the networks\n",
    "if type_net=='ER':\n",
    "    p = 0.4 # Probability of edge creation\n",
    "elif type_net=='BA':\n",
    "    m = 0.4 # Fraction of nodes\n",
    "elif type_net=='Power-law':\n",
    "    m, p = 1, .1\n",
    "elif type_net=='DSF':\n",
    "    pass\n",
    "else:\n",
    "    raise ValueError(\"Network not implemented\")\n",
    "\n",
    "# Generation of the networks\n",
    "if type_net=='ER':\n",
    "    try:\n",
    "        Graphs = np.load(f\"./{type_net}/graphs-{NUM_NETWORKS}_p-{p}.npy\", allow_pickle=True)\n",
    "    except:\n",
    "        Graphs = np.empty(shape=(len(num_nodes),), dtype=object)\n",
    "        for i, n in enumerate(num_nodes):\n",
    "            Graphs[i] = [nx.erdos_renyi_graph(n=int(n), p=p) for _ in range(NUM_NETWORKS)]\n",
    "        np.save(f\"./{type_net}/graphs-{NUM_NETWORKS}_p-{p}.npy\", Graphs)        \n",
    "\n",
    "elif type_net=='BA':\n",
    "    try:\n",
    "        Graphs = np.load(f\"./{type_net}/graphs-{NUM_NETWORKS}_m-{m}.npy\", allow_pickle=True)\n",
    "    except:\n",
    "        Graphs = np.empty(shape=(len(num_nodes),), dtype=object)\n",
    "        for i, n in enumerate(num_nodes):\n",
    "            Graphs[i] = [nx.barabasi_albert_graph(n=n, m=int(n*m)) for _ in range(NUM_NETWORKS)]\n",
    "        np.save(f\"./{type_net}/graphs-{NUM_NETWORKS}_m-{m}.npy\", Graphs)\n",
    "\n",
    "elif type_net=='Power-law':\n",
    "    try:\n",
    "        Graphs = np.load(f\"./{type_net}/graphs-{NUM_NETWORKS}_m-{m}_p-{p}.npy\", allow_pickle=True)\n",
    "    except:\n",
    "        Graphs = np.empty(shape=(len(num_nodes),), dtype=object)\n",
    "        for i, n in enumerate(num_nodes):\n",
    "            Graphs[i] = [nx.powerlaw_cluster_graph(n=n, m=m, p=p) for _ in range(NUM_NETWORKS)]\n",
    "        np.save(f\"./{type_net}/graphs-{NUM_NETWORKS}_m-{m}_p-{p}.npy\", Graphs)\n",
    "\n",
    "elif type_net=='DSF':\n",
    "    pass\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"Network not implemented\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Community structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reasults loaded for n=10.0\n",
      "Reasults loaded for n=20.0\n",
      "Reasults loaded for n=30.0\n",
      "Reasults loaded for n=40.0\n",
      "Reasults loaded for n=50.0\n",
      "Reasults loaded for n=60.0\n",
      "Reasults loaded for n=70.0\n",
      "Reasults loaded for n=80.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Networks with 90.0 nodes completed::   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [03:44<00:00, 11.24s/it]\n",
      "Networks with 90.0 nodes completed:: 100%|██████████| 1/1 [03:46<00:00, 226.08s/it]\n",
      "100%|██████████| 20/20 [05:03<00:00, 15.17s/it]      | 0/1 [00:00<?, ?it/s]\n",
      "Networks with 100.0 nodes completed:: 100%|██████████| 1/1 [05:04<00:00, 304.63s/it]\n"
     ]
    }
   ],
   "source": [
    "### ADVANTAGE ANNEALING ###\n",
    "adv_modularities = np.zeros((num_nodes.shape[0], NUM_NETWORKS))\n",
    "adv_communities = np.empty((num_nodes.shape[0], NUM_NETWORKS), dtype=object)\n",
    "adv_times_elapsed = np.zeros((num_nodes.shape[0], NUM_NETWORKS))\n",
    "\n",
    "for i, G_nodes in enumerate(num_nodes):\n",
    "    try:\n",
    "        adv_modularities[i] = np.load(f\"./{type_net}/solver-adv_runs-{num_runs}_nodes-{G_nodes}_modularities.npy\")\n",
    "        adv_communities[i] = np.load(f\"./{type_net}/solver-adv_runs-{num_runs}_nodes-{G_nodes}_communities.npy\", allow_pickle=True)\n",
    "        adv_times_elapsed[i] = np.load(f\"./{type_net}/solver-adv_runs-{num_runs}_nodes-{G_nodes}_times.npy\")\n",
    "        print(f\"Reasults loaded for n={G_nodes}\")\n",
    "    except:        \n",
    "        for j, G in enumerate(tqdm(Graphs[i], desc=f\"Networks with {G_nodes} nodes completed:\")):\n",
    "            adv_sampler = AdvantageSampler(G, resolution=resolution, num_reads=100, use_clique_embedding=True)\n",
    "            adv_searcher = HierarchicalCommunitySearcher(adv_sampler)\n",
    "            adv_iterative= IterativeSearcher(adv_searcher)\n",
    "            cs_all, mod_all, ts_all = adv_iterative.run(num_runs=num_runs, save_results=False)\n",
    "\n",
    "            # Only the community with the highest modularity\n",
    "            adv_communities[i,j] = cs_all[mod_all.argmax()]\n",
    "            adv_modularities[i,j] = mod_all.max()\n",
    "            adv_times_elapsed[i,j] = ts_all[mod_all.argmax()]\n",
    "\n",
    "        np.save(f\"./{type_net}/solver-adv_runs-{num_runs}_nodes-{G_nodes}_modularities.npy\", adv_modularities[i])\n",
    "        np.save(f\"./{type_net}/solver-adv_runs-{num_runs}_nodes-{G_nodes}_communities.npy\", adv_communities[i], allow_pickle=True)\n",
    "        np.save(f\"./{type_net}/solver-adv_runs-{num_runs}_nodes-{G_nodes}_times.npy\", adv_times_elapsed[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 540.30it/s]    | 0/1 [00:00<?, ?it/s]\n",
      "Networks with 10.0 nodes completed:: 100%|██████████| 1/1 [00:00<00:00, 24.93it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 283.93it/s]    | 0/1 [00:00<?, ?it/s]\n",
      "Networks with 20.0 nodes completed:: 100%|██████████| 1/1 [00:00<00:00, 13.67it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 328.93it/s]    | 0/1 [00:00<?, ?it/s]\n",
      "Networks with 30.0 nodes completed:: 100%|██████████| 1/1 [00:00<00:00, 15.67it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 156.49it/s]    | 0/1 [00:00<?, ?it/s]\n",
      "Networks with 40.0 nodes completed:: 100%|██████████| 1/1 [00:00<00:00,  7.67it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 82.39it/s]     | 0/1 [00:00<?, ?it/s]\n",
      "Networks with 50.0 nodes completed:: 100%|██████████| 1/1 [00:00<00:00,  4.06it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 56.74it/s]     | 0/1 [00:00<?, ?it/s]\n",
      "Networks with 60.0 nodes completed:: 100%|██████████| 1/1 [00:00<00:00,  2.81it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 65.92it/s]     | 0/1 [00:00<?, ?it/s]\n",
      "Networks with 70.0 nodes completed:: 100%|██████████| 1/1 [00:00<00:00,  3.27it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 42.16it/s]     | 0/1 [00:00<?, ?it/s]\n",
      "Networks with 80.0 nodes completed:: 100%|██████████| 1/1 [00:00<00:00,  2.10it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 36.21it/s]     | 0/1 [00:00<?, ?it/s]\n",
      "Networks with 90.0 nodes completed:: 100%|██████████| 1/1 [00:00<00:00,  1.79it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 28.33it/s]      | 0/1 [00:00<?, ?it/s]\n",
      "Networks with 100.0 nodes completed:: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n"
     ]
    }
   ],
   "source": [
    "### LOUVAIN ###\n",
    "try:\n",
    "    louv_modularities = np.load(f\"./{type_net}/solver-louv_runs-{num_runs}_modularities.npy\")\n",
    "    louv_communities = np.load(f\"./{type_net}/solver-louv_runs-{num_runs}_communities.npy\", allow_pickle=True)\n",
    "    louv_times_elapsed = np.load(f\"./{type_net}/solver-louv_runs-{num_runs}_times.npy\")\n",
    "    print(\"Reasults loaded\")\n",
    "except:\n",
    "    louv_modularities = np.zeros((num_nodes.shape[0], NUM_NETWORKS))\n",
    "    louv_communities = np.empty((num_nodes.shape[0], NUM_NETWORKS), dtype=object)\n",
    "    louv_times_elapsed = np.zeros((num_nodes.shape[0], NUM_NETWORKS))\n",
    "\n",
    "    for i, G_nodes in enumerate(num_nodes):\n",
    "        for j, G in enumerate(tqdm(Graphs[i], desc=f\"Networks with {G_nodes} nodes completed:\")):\n",
    "            louv_sampler = LouvainSampler(G, resolution=resolution)\n",
    "            louv_searcher = CommunitySearcher(louv_sampler)\n",
    "            louv_iterative= IterativeSearcher(louv_searcher)\n",
    "            cs_all, mod_all, ts_all = louv_iterative.run(num_runs=num_runs, save_results=False)\n",
    "\n",
    "            # Only the community with the highest modularity\n",
    "            louv_communities[i,j] = cs_all[mod_all.argmax()]\n",
    "            louv_modularities[i,j] = mod_all.max()\n",
    "            louv_times_elapsed[i,j] = ts_all[mod_all.argmax()]\n",
    "\n",
    "    np.save(f\"./{type_net}/solver-louv_runs-{num_runs}_modularities.npy\", louv_modularities)\n",
    "    np.save(f\"./{type_net}/solver-louv_runs-{num_runs}_communities.npy\", louv_communities, allow_pickle=True)\n",
    "    np.save(f\"./{type_net}/solver-louv_runs-{num_runs}_times.npy\", louv_times_elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 765.31it/s]    | 0/1 [00:00<?, ?it/s]\n",
      "Networks with 10.0 nodes completed:: 100%|██████████| 1/1 [00:00<00:00, 34.98it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 564.93it/s]    | 0/1 [00:00<?, ?it/s]\n",
      "Networks with 20.0 nodes completed:: 100%|██████████| 1/1 [00:00<00:00, 26.01it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 506.59it/s]    | 0/1 [00:00<?, ?it/s]\n",
      "Networks with 30.0 nodes completed:: 100%|██████████| 1/1 [00:00<00:00, 23.37it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 319.89it/s]    | 0/1 [00:00<?, ?it/s]\n",
      "Networks with 40.0 nodes completed:: 100%|██████████| 1/1 [00:00<00:00, 15.32it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 304.66it/s]    | 0/1 [00:00<?, ?it/s]\n",
      "Networks with 50.0 nodes completed:: 100%|██████████| 1/1 [00:00<00:00, 14.66it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 183.01it/s]    | 0/1 [00:00<?, ?it/s]\n",
      "Networks with 60.0 nodes completed:: 100%|██████████| 1/1 [00:00<00:00,  8.92it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 133.83it/s]    | 0/1 [00:00<?, ?it/s]\n",
      "Networks with 70.0 nodes completed:: 100%|██████████| 1/1 [00:00<00:00,  6.52it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 85.07it/s]     | 0/1 [00:00<?, ?it/s]\n",
      "Networks with 80.0 nodes completed:: 100%|██████████| 1/1 [00:00<00:00,  4.19it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 63.98it/s]     | 0/1 [00:00<?, ?it/s]\n",
      "Networks with 90.0 nodes completed:: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 64.19it/s]      | 0/1 [00:00<?, ?it/s]\n",
      "Networks with 100.0 nodes completed:: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s]\n"
     ]
    }
   ],
   "source": [
    "### LEIDEN ###\n",
    "try:\n",
    "    leid_modularities = np.load(f\"./{type_net}/solver-leid_runs-{num_runs}_modularities.npy\")\n",
    "    leid_communities = np.load(f\"./{type_net}/solver-leid_runs-{num_runs}_communities.npy\", allow_pickle=True)\n",
    "    leid_times_elapsed = np.load(f\"./{type_net}/solver-leid_runs-{num_runs}_times.npy\")\n",
    "    print(\"Reasults loaded\")\n",
    "except:\n",
    "    leid_modularities = np.zeros((num_nodes.shape[0], NUM_NETWORKS))\n",
    "    leid_communities = np.empty((num_nodes.shape[0], NUM_NETWORKS), dtype=object)\n",
    "    leid_times_elapsed = np.zeros((num_nodes.shape[0], NUM_NETWORKS))\n",
    "\n",
    "    for i, G_nodes in enumerate(num_nodes):\n",
    "        for j, G in enumerate(tqdm(Graphs[i], desc=f\"Networks with {G_nodes} nodes completed:\")):\n",
    "            leid_sampler = LeidenSampler(G)\n",
    "            leid_searcher = CommunitySearcher(leid_sampler)\n",
    "            leid_iterative= IterativeSearcher(leid_searcher)\n",
    "            cs_all, mod_all, ts_all = leid_iterative.run(num_runs=num_runs, save_results=False)\n",
    "\n",
    "            # Only the community with the highest modularity\n",
    "            leid_communities[i,j] = cs_all[mod_all.argmax()]\n",
    "            leid_modularities[i,j] = mod_all.max()\n",
    "            leid_times_elapsed[i,j] = ts_all[mod_all.argmax()]\n",
    "\n",
    "    np.save(f\"./{type_net}/solver-leid_runs-{num_runs}_modularities.npy\", leid_modularities)\n",
    "    np.save(f\"./{type_net}/solver-leid_runs-{num_runs}_communities.npy\", leid_communities, allow_pickle=True)\n",
    "    np.save(f\"./{type_net}/solver-leid_runs-{num_runs}_times.npy\", leid_times_elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.00836682],\n",
       "        [0.00184011],\n",
       "        [0.00159335],\n",
       "        [0.00329041],\n",
       "        [0.0040009 ]]),\n",
       " array([[0.00831127],\n",
       "        [0.00213552],\n",
       "        [0.00193143],\n",
       "        [0.0094347 ],\n",
       "        [0.00843358]]),\n",
       " array([[ 6.64670587],\n",
       "        [ 6.78401995],\n",
       "        [13.08130765],\n",
       "        [14.32917356],\n",
       "        [18.37536287]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leid_times_elapsed[:5], louv_times_elapsed[:5], adv_times_elapsed[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dwave_playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
